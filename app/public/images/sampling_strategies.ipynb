{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc567ddb-51dc-40ff-bbc0-0709317b69c4",
   "metadata": {},
   "source": [
    "### Random Sample Function in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce78dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 5, 8]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample([1,2,3,4,5,6,7,8,9,10], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ac011b-cbae-42aa-aa71-46b6da5ff866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, False, False, False, False, True, False]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = random.choices([True, False], weights=[0.1, 0.9], k=100)\n",
    "data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4db18aff-56c4-4cb5-8124-0eb039f22d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 93, True: 7})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b4a27f-b78d-45fb-9490-8fcabd8f05b3",
   "metadata": {},
   "source": [
    "## Why Reduce Big Data?\n",
    "\n",
    "* Despite the importance of \"big data\", sometimes using the entire dataset is infeasible, impractical, or expensive.\n",
    "\n",
    "1. Storage Limitations: \n",
    "   - Many applications can't keep all the data is is collected\n",
    "   - Example: A large ISP might generate petabytes of log data daily\n",
    "\n",
    "2. Convenience: \n",
    "   - Working with smaller datasets is often more manageable\n",
    "   - It's easier to experiment and iterate on smaller data\n",
    "\n",
    "3. Speed: \n",
    "   - Analyzing a compact summary is faster than processing the entire dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd958f-8c3a-447c-9d44-0d8aca1ff4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Why Sample?\n",
    "\n",
    "Sampling is a powerful technique for reducing big data. Here's why it's often the go-to method:\n",
    "\n",
    "1. Intuitive Semantics: \n",
    "   - We get a smaller dataset that maintains the structure of the original\n",
    "   - It's like taking a small scoop from a large pot of soup to taste it\n",
    "\n",
    "2. Straightforward Estimation: \n",
    "   - We can often run the same analysis on the sample as on the full data\n",
    "   - We just need to apply some rescaling to our results\n",
    "\n",
    "3. General and Agnostic: \n",
    "   - Sampling works for many types of analyses\n",
    "   - Unlike some summary methods that only work for specific computations\n",
    "\n",
    "4. Easy to Understand: \n",
    "   - Most people have an intuition about how sampling works\n",
    "   - This makes it easier to explain your methods to non-technical stakeholders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad19f1be-7fd3-4c90-9327-c139e340f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sampling as a Mediator of Constraints\n",
    "\n",
    "In real-world applications, sampling often acts as a bridge between various constraints:\n",
    "\n",
    "1. Data Characteristics:\n",
    "   - Examples: Heavy-tailed distributions, correlations between variables\n",
    "   - Challenge: These can make simple random sampling less effective\n",
    "\n",
    "2. Query Requirements:\n",
    "   - Examples: Need for ad-hoc queries, high accuracy, fast aggregations\n",
    "   - Challenge: Different requirements may need different sampling strategies\n",
    "\n",
    "3. Resource Constraints:\n",
    "   - Examples: Limited bandwidth, storage, or CPU power\n",
    "   - Challenge: We need to sample in a way that respects these limitations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d3905",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sampling Terminology.\n",
    "\n",
    "* In statistical language, the full dataset is termed the **population**, while the subset is called a **sample**.\n",
    "* There are various methods and strategies for sampling.\n",
    "    *  They all provide a condensed version of the data for efficient processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653af2f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sampling\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://www.dropbox.com/s/vzr0w2cvx6b5bm0/sampling.png?dl=1\" width=\"700\" alt=\"Sampling Image\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b2552e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representing Data \n",
    "\n",
    "* For a dataset with D variables, a data point can be visualized as a point in a D-dimensional space.\n",
    "  * For instance, a dataset with two variables can be represented in two dimensions.\n",
    "<div align=\"center\">\n",
    "<img src=\"https://www.dropbox.com/s/t0ca5t1qzkr635b/2d-data.png?dl=1\" alt=\"Drawing\" width=\"700px;\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ef0135",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representing Data  -- Example\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://www.dropbox.com/s/sy00s9t8bq0wbxb/data_2d.png?dl=1\" alt=\"Drawing\" width=\"900px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ef807",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representing Data  -- Higher Dimensional Space\n",
    "<div align=\"center\">\n",
    "<img src=\"https://www.dropbox.com/s/4flfaojlfb2a101/3d-data.png?dl=1\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcfaed9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Subsampling\n",
    "\n",
    "* Subsampling is a specific type of sampling where you take a smaller sample from an already obtained sample rather than from the whole population\n",
    "  * The terms sampling and subsampling are often used interchangeably\n",
    "\n",
    "* Different methods can be used to subsample.\n",
    "  * A simple method might involve selecting the first half of the data and discarding the rest.\n",
    "    * This is not always effective, especially if the data is organized (i.e., sorted) based on specific attributes, such as gender.\n",
    "* Several more sophisticated sampling strategies exist to efficiently reduce dataset size, especially for big data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b10dfd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Subsample\n",
    "* Random subsampling is a method returns random sub-samples from a collection.\n",
    "* Each item has an equal chance of being selected.\n",
    "* Best suited for datasets that:\n",
    "  * Have relatively balanced category proportions.\n",
    "  * Don't need to specifically account for or analyze the edge cases or outliers in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86ecd74-ae6d-4057-8f7a-110d8f3d093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli Sampling\n",
    "\n",
    "- **Simplest case**: All weights are 1\n",
    "  - N objects, sample k uniformly\n",
    "  - Each k-subset equally likely\n",
    "\n",
    "- **Method**: Sample index from N (no replacement) k times\n",
    "  - Note: Generating true random numbers on computers?\n",
    "  - Assume random number generators are good enough\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c5e3c57",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample([1,2,3,4,5], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2276f04-1905-4f31-b319-386939f1b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bernouilli Sampling\n",
    "- **Streaming Challenge**: Single linear scan to draw sample\n",
    "  - Streaming computation: see each element once\n",
    "  - Application: Streaming sensor data.\n",
    "  - Common tech interview question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab3e7781-fed0-4a17-894a-07f19f510651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of 10 items: [267, 518, 899, 27, 77, 925, 415, 395, 83, 521]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def reservoir_sample(stream, k):\n",
    "    reservoir = []\n",
    "    for i, item in enumerate(stream):\n",
    "        if i < k:\n",
    "            reservoir.append(item)\n",
    "        else:\n",
    "            # Randomly decide whether to include the current item in the reservoir\n",
    "            j = random.randint(0, i)\n",
    "            if j < k:\n",
    "                reservoir[j] = item\n",
    "    return reservoir\n",
    "\n",
    "stream = range(1000) \n",
    "sample_size = 10\n",
    "result = reservoir_sample(stream, sample_size)\n",
    "print(f\"Sample of {sample_size} items: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b35dec5-5ad7-4ea5-a987-0f8cffcfb989",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Order Sampling\n",
    "\n",
    "* Also referred to bottom-k sampling\n",
    "  * Alternative method for reservoir sampling\n",
    "* Approach \n",
    "  * We generate a random tag (a float between 0 and 1) for the item.\n",
    "  * If we haven't filled our reservoir (heap) to size k yet, we add the item to the heap.\n",
    "  * If our heap is full, we compare the new item's tag to the largest tag in the heap (which is at the root of the max heap).\n",
    "  * If the new tag is smaller, we remove the item with the largest tag and add the new item.\n",
    "\n",
    "* It processes the stream in a single pass, using O(k) additional memory.\n",
    "* It's easily parallelizable. You can run this on multiple streams and then merge the results by keeping the k items with the smallest tags across all streams.\n",
    "* It's efficient, with O(log k) time complexity per item due to heap operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3d01ddc-efc3-481a-9d36-70b19fe62566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of 10 items: [86, 576, 742, 572, 952, 669, 329, 195, 469, 956]\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import random\n",
    "\n",
    "def order_sampling(stream, k):\n",
    "    heap = []\n",
    "    \n",
    "    for item in stream:\n",
    "        tag = random.random()\n",
    "        \n",
    "        if len(heap) < k:\n",
    "            heapq.heappush(heap, (-tag, item))\n",
    "        elif -tag > heap[0][0]:\n",
    "            # If the new item's tag is smaller than the largest in the heap,\n",
    "            # remove the largest and add the new item\n",
    "            heapq.heappop(heap)\n",
    "            heapq.heappush(heap, (-tag, item))\n",
    "    \n",
    "    # Return the items (without their tags) in arbitrary order\n",
    "    return [item for _, item in heap]\n",
    "\n",
    "stream = range(1000) \n",
    "sample_size = 10\n",
    "result = order_sampling(stream, sample_size)\n",
    "print(f\"Sample of {sample_size} items: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3ff7d3-af15-4545-93d1-663e6e9defa6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Special Cases\n",
    "\n",
    "* While random subsampling treats data points equally, there are scenarios where our data has more complex structures or patterns.\n",
    "  * For example, We might want our sample to mirror certain characteristics of the full dataset or ensure specific segments are represented.\n",
    "\n",
    "* For this, we turn to subsampling, a broader umbrella term that encompasses various methods including random and stratified subsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cd3c50-a961-44a4-80e6-230c6e86dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weighted Random Sampling\n",
    "* This method generalizes min-wise sampling and can be proven to provide the correct sampling distribution.\n",
    "* For each item, draw a random number $r_n$ uniformly from [0,1].\n",
    "* Compute the 'tag' of an item as $r_n^{(1/x_n)}$, where $x_n$ is the item's weight.\n",
    "* Keep the k items with the smallest tags.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489dc561-ccd3-4898-9188-6e067a4842e6",
   "metadata": {},
   "source": [
    "## Weighted Random Sampling -- Example\n",
    "\n",
    "Item A: weight 3\n",
    "Item B: weight 1\n",
    "Item C: weight 2\n",
    "Item D: weight 4\n",
    "Step 1: Generate random numbers and calculate tags\n",
    "A: r_A = 0.6, tag_A = 0.6^(1/3) ≈ 0.843\n",
    "B: r_B = 0.2, tag_B = 0.2^(1/1) = 0.200\n",
    "C: r_C = 0.8, tag_C = 0.8^(1/2) ≈ 0.894\n",
    "D: r_D = 0.5, tag_D = 0.5^(1/4) ≈ 0.841\n",
    "Step 2: Keep track of the 2 largest tags\n",
    "After A: [A(0.843)]\n",
    "After B: [A(0.843), B(0.200)]\n",
    "After C: [C(0.894), A(0.843)]\n",
    "After D: [C(0.894), A(0.843)] (D's tag is smaller than A's, so it's not included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce965b4-42b9-4f38-9ad1-3f7b433a8676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priority Sampling\n",
    "\n",
    "- Each item $x_i$ given priority $z_i = $x_i / ri_$ with rn uniform random in (0,1)\n",
    "\n",
    "- Maintain reservoir of $k+1$ items ($x)i$, $z_i$) of highest priority\n",
    "\n",
    "- Estimation\n",
    "  - Let z* = (k+1)st highest priority\n",
    "  - Top-k priority items: weight estimate x'i = max{ xi, z* }\n",
    "  - All other items: weight estimate zero\n",
    "\n",
    "- Statistics and bounds\n",
    "  - x'i unbiased; zero covariance: Cov[x'i, x'j] = 0 for i≠j\n",
    "  - Relative variance for any subset sum ≤ 1/(k-1) [Szegedy, 2006]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd41769-5119-4f36-8548-7277626e75ea",
   "metadata": {},
   "source": [
    "# Priority Sampling - Example\n",
    "\n",
    "* Step 1: Generate random numbers and calculate priorities\n",
    "Item A: weight 15, rA = 0.3, zA = 15 / 0.3 = 50\n",
    "Item B: weight 8,  rB = 0.1, zB = 8 / 0.1 = 80\n",
    "Item C: weight 12, rC = 0.4, zC = 12 / 0.4 = 30\n",
    "Item D: weight 20, rD = 0.8, zD = 20 / 0.8 = 25\n",
    "Item E: weight 6,  rE = 0.05, zE = 6 / 0.05 = 120\n",
    "Item F: weight 18, rF = 0.6, zF = 18 / 0.6 = 30\n",
    "Item G: weight 10, rG = 0.2, zG = 10 / 0.2 = 50\n",
    "Item H: weight 5,  rH = 0.25, zH = 5 / 0.25 = 20\n",
    "\n",
    "\n",
    "* Step 2: Maintain reservoir of k+1 (4) items with highest priorities\n",
    "After A: [(A, 50)]\n",
    "After B: [(B, 80), (A, 50)]\n",
    "After C: [(B, 80), (A, 50), (C, 30)]\n",
    "After D: [(B, 80), (A, 50), (C, 30), (D, 25)]\n",
    "After E: [(E, 120), (B, 80), (A, 50), (C, 30)]\n",
    "After F: [(E, 120), (B, 80), (A, 50), (F, 30)]\n",
    "After G: [(E, 120), (B, 80), (G, 50), (A, 50)]\n",
    "After H: [(E, 120), (B, 80), (G, 50), (A, 50)] (H's priority is lower, so it's not included)\n",
    "\n",
    "* Step 3: Estimation\n",
    "z* (4th highest priority) = 50\n",
    "Weight estimates:\n",
    "E: x'E = max(6, 50) = 50\n",
    "B: x'B = max(8, 50) = 50\n",
    "G: x'G = max(10, 50) = 50\n",
    "A: x'A = max(15, 50) = 50\n",
    "C: x'C = 0 (not in top-k)\n",
    "D: x'D = 0 (not in top-k)\n",
    "F: x'F = 0 (not in top-k)\n",
    "H: x'H = 0 (not in top-k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcd07a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stratified Random Sampling\n",
    "\n",
    "* Utilized when data can be associated with specific subgroups.\n",
    "* It ensures that the sample retains the distribution of values for specific features present in the entire population.\n",
    "* This approach maintains the population's structure by:\n",
    "  1. Divides the population into homogeneous subgroups or strata.\n",
    "  2. Selects elements from each stratum in proportion to the stratum's size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff80728",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Subsampling from Labeled Data\n",
    "\n",
    "* Unlabeled Data: If data doesn't have predefined categories or strata, how do you ensure a representative sample?\n",
    "\n",
    "* For such data, we can create 'hypothetical' groups or strata using clustering.\n",
    "\n",
    "* Clustering works by grouping data points based on how similar they are, ensuring that members of one group are more alike than those in other groups.\n",
    "  * Explicit Selection: Sometimes, we need a sample from each category or group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65edd13c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stratified Random Sampling - Cont'd\n",
    "\n",
    "* Instances in the population are first divided into homogenous subgroups known as strata\n",
    "* The number of elements selected in each stratum is proportional to the size of the stratum\n",
    "  * Thus maintaining the structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c3d083",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representation of an Observation\n",
    "\n",
    "* Recall that data points can be represented as a point in high-dimensional space\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"https://www.dropbox.com/s/jbriqx9i7jyloyl/data_clusts_1.png?dl=1\" alt=\"drawing\" width=\"500\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ad6fc4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Identifying Clusters\n",
    "<div align=\"center\">\n",
    "<img src=\"https://www.dropbox.com/s/jb81jew9hyf44pp/data_clusts_2.png?dl=1\" alt=\"drawing\" width=\"500\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0efdd94",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cluster-Based Sampling \n",
    "* Cluster before vs. Cluster after Sampling.\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://www.dropbox.com/s/bkd32khr1q8dfhx/before_after.png?dl=1\" alt=\"drawing\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f32206c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cluster-Based Sampling: Kernel-Based Importance Sampling \n",
    "\n",
    "* How can select instances from a cluster?\n",
    "  * Which ones should we pick?\n",
    "\n",
    "* Select with probability inversely proportional to the distance of the cluster center\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"https://www.dropbox.com/s/ncrusv71mylkat8/dist_to_center.png?dl=1\" alt=\"drawing\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6e72d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cluster-Based Sampling:  Weighted Density Sampling\n",
    "\n",
    "* Weighted density sampling is a method used to select (or discard) events based on their local density.\n",
    "  * The probability that a data point will be sampled is determined by its local density; that is, the density around that specific data point.\n",
    "* Local density is defined as the number of data points within a given radius of that point.\n",
    "* The radius used is typically defined by the user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f76f2b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cluster-Based Sampling\n",
    "\n",
    "* Advantages:\n",
    "  * Efficient once clusters are defined.\n",
    "  * Can be adjusted to pick points close center or more representative of periphery.\n",
    "\n",
    "* Limitations:\n",
    "  * Determining the number of clusters can be challenging.\n",
    "  * The presence of outliers or noisy observations can skew clustering.\n",
    "  * Might distort the shape of clusters, complicating subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54b2a29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grid-based Sampling\n",
    "\n",
    "* How can we sample from this?\n",
    "  * No clear clusters\n",
    "    \n",
    "![](https://www.dropbox.com/scl/fi/b2nytya0izd1g1jbxnwre/map.png?rlkey=qhdprfbd2yqutt5q28lm3fgne&dl=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84095be0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grid-based Sampling\n",
    "\n",
    "![](https://www.dropbox.com/scl/fi/tfc8wr3ju8unzm6sp2r7i/grid_on_map.png?rlkey=yw2fvr65eltophw1tsha4yd1s&dl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e14162",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grid-based Sampling\n",
    "\n",
    "* Divide the data into grid cells and select a number of points per cell\n",
    "  * It is possible to choose a fixed number of points or to select points based on some cell-specific criteria\n",
    "\n",
    "* Provides an organized way of ensuring that samples are spread out across the data space\n",
    "  * Especially important when the distribution of data points is uneven.\n",
    "\n",
    "* Ideal for spatial and Geospatial Data\n",
    "![](https://www.dropbox.com/s/nijshpr93rth8fn/grid.png?dl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1793b282-b776-4f75-b17f-7daae79d9277",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  Grid-based Sampling\n",
    "* Advantages:\n",
    "  * Ensures that the entire data space is uniformly represented.\n",
    "    * Mitigate the risk of sampling bias, especially in areas of sparse data,   \n",
    "  * Can take either a fixed number of points from each cell or use cell-specific criterion\n",
    "  * The grid is natural stratification of the data space\n",
    "    \n",
    "* Limitations:  \n",
    "  * The size and shape of the grid cells can influence the sampling results.\n",
    "    * Too large a grid might miss localized patterns, while too small a grid might lead to over-representation of noisy patterns.\n",
    "  * Can be computationally intenstive, especially for high-dimensional data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53920acf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grid-based Sampling Using Random Projections: An intuition\n",
    "\n",
    "* Step 1: Given some randomly selected line that passes at the origin, project a point that define Vector A so that the projection is perpendicular to that line and new projection is represented uing vector A'\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://www.dropbox.com/s/wdiqdrphg0wzhmi/a_b_projected.png?dl=1\" alt=\"drawing\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028eecc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grid-based Sampling Using Random Projections: An intuition\n",
    "\n",
    "* Step 2: select a vector that starts at the oringin and is embedded in the selected lines and normalize by the vector's magnitude.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/bqaeehgtvm9c9ga/a_b_line.png?dl=1\" alt=\"drawing\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d586d272-2b5e-43fe-b18a-7118e8d104fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding Orthogonal Vectors\n",
    "\n",
    "* Step 3: Repeat using an orthogonal (or perpendicular) vetor.\n",
    "\n",
    "* To find a vector that is orthogonal  to a given vector, you need a vector whose dot product with the given vector is zero.\n",
    "\n",
    "* Given vector $ \\mathbf{v} = \\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix} $.\n",
    "\n",
    "To find a vector $ \\mathbf{u} = \\begin{bmatrix} x \\\\ y \\end{bmatrix} $ that is orthogonal to $ \\mathbf{v} $, the dot product $ \\mathbf{u} \\cdot \\mathbf{v} $ must be zero:\n",
    "\n",
    "$$ \n",
    "\\mathbf{u} \\cdot \\mathbf{v} = 5x + 2y = 0 \n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e21125-cbc0-4463-a801-f98ec71fe2e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding Orthogonal Vectors -- cont'd\n",
    "\n",
    "* One way to find an orthogonal vector is to swap the components and negate one of them. Using this method:\n",
    "\n",
    "* If $ \\mathbf{v} = \\begin{bmatrix} a \\\\ b \\end{bmatrix} $, Then an orthogonal $ \\mathbf{u} $ can be $ \\begin{bmatrix} -b \\\\ a \\end{bmatrix} $.\n",
    "\n",
    "\n",
    "* There are infinitely many vectors orthogonal to $ \\mathbf{v} $, but $ \\begin{bmatrix} -2 \\\\ 5 \\end{bmatrix} $ is one of the simplest ones.   * You could scale this vector by any scalar, and it would still be orthogonal to $ \\mathbf{v} $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debbbc3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Project on New Orthogonal Vectors\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/wf0nh45do2193i8/a_b_vec_2.png?dl=1\" alt=\"drawing\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8366c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convert to New Space (Grid)\n",
    "\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/ggohljkopdi6l6n/a_b_new_space.png?dl=1\" alt=\"drawing\" width=\"800\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010ae54",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Similarity Preserving Projection Based Approach\n",
    "\n",
    "* Pros:\n",
    "  * Offers theoretical guarantees that points close in high-dimensional space will be assigned to the same grid elements (buckets).\n",
    "    * Reference: Johnson–Lindenstrauss lemma\n",
    "  * Computationally efficient.\n",
    "  * Easily and swiftly computed on GPUs.\n",
    "  * Effective with wide data sets.\n",
    "\n",
    "* Cons:\n",
    "  * Probabilistic nature results in an infinite number of potential grids to select from.\n",
    "  * Although a 2-D grid is chosen, grids in a much higher-dimensional space may be required based on the data's dimensionality.\n",
    "  * Assessing the quality of resulting bins can be labor-intensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411aa67c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Projection as a Dot Product\n",
    "\n",
    "* How do you project a point onto a new axis?\n",
    " \n",
    "* The dot product (or inner product) of two vectors provides the projection of one vector onto the line spanned by the other.\n",
    "\n",
    "* This projection describes the vector in terms of the reference vector.\n",
    "  * After normalization, the quantity represents the magnitude of the projected vector relative to the reference vector.\n",
    "\n",
    "$$\n",
    "\\text{Proj}_{B}A = \\frac{A \\cdot B}{|B|}\n",
    "$$\n",
    "where $A \\cdot B$ is the dot product of vectors A and B.\n",
    "\n",
    "$$\n",
    "A \\cdot B = \\sum_{i=1}^{n} A_i \\times B_i \n",
    "$$\n",
    "\n",
    "Here, $n$ is the dimension of vectors $A$ and $B$. $|B|$ denotes the magnitude of vector $B$, and it's computed as:\n",
    "\n",
    "$$\n",
    "|B| = \\sqrt{\\sum B_i^2}\n",
    "$$\n",
    "\n",
    "The numerator is used to normalize the resulting quantity, expressing it in terms of vector B.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "467aa56f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The magnitude of B is: 5.385164807134504\n",
      "The magnitude of the projection  4.270992778072193\n",
      "The ratio of the projection in terms of B is 0.7931034482758621\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# compute the normalized projection of A onto B.\n",
    "A = (3,4)\n",
    "B = (5,2)\n",
    "\n",
    "A_dot_B = A[0]*B[0] + A[1]*B[1]\n",
    "amp_B = math.sqrt(B[0]**2 + B[1]**2)\n",
    "print(f\"The magnitude of B is: {amp_B}\")\n",
    "proj = A_dot_B / amp_B\n",
    "print (f\"The magnitude of the projection  {proj}\")\n",
    "\n",
    "print(f\"The ratio of the projection in terms of B is {proj/amp_B}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ba1d4f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<img src=\"https://www.dropbox.com/s/ggohljkopdi6l6n/a_b_new_space.png?dl=1\" alt=\"drawing\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "129d89a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The magnitude of D is: 4.47213595499958\n",
      "\n",
      "The magnitude of the projection  4.427414595449584\n",
      "The ratio of the projection in terms of D is 0.99\n",
      "Projection occurs in bin 1 \n",
      "\n",
      "The magnitude of the projection  7.602631123499284\n",
      "The ratio of the projection in terms of D is 1.6999999999999997\n",
      "Projection occurs in bin 2 \n",
      "\n",
      "The magnitude of the projection  8.497058314499201\n",
      "The ratio of the projection in terms of D is 1.9\n",
      "Projection occurs in bin 2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Projection as a Dot Product\n",
    "\n",
    "A = (0.95, 8)\n",
    "B = (5,7)\n",
    "C = (6,5)\n",
    "D = (4,2)\n",
    "\n",
    "amp_D = math.sqrt(D[0]**2 + D[1]**2)\n",
    "print(f\"The magnitude of D is: {amp_D}\\n\")\n",
    "\n",
    "\n",
    "A_dot_D = A[0]*D[0] + A[1]*D[1]\n",
    "proj_A = A_dot_D / amp_D\n",
    "print (f\"The magnitude of the projection  {proj_A}\")\n",
    "print(f\"The ratio of the projection in terms of D is {proj_A/amp_D}\")\n",
    "print(f\"Projection occurs in bin {math.ceil(proj_A/amp_D)} \\n\")\n",
    "\n",
    "\n",
    "B_dot_D = B[0]*D[0] + B[1]*D[1]\n",
    "proj_B = B_dot_D / amp_D\n",
    "print (f\"The magnitude of the projection  {proj_B}\")\n",
    "print(f\"The ratio of the projection in terms of D is {proj_B/amp_D}\")\n",
    "print(f\"Projection occurs in bin {math.ceil(proj_B/amp_D)} \\n\")\n",
    "\n",
    "\n",
    "C_dot_D = C[0]*D[0] + B[1]*D[1]\n",
    "proj_C = C_dot_D / amp_D\n",
    "print (f\"The magnitude of the projection  {proj_C}\")\n",
    "print(f\"The ratio of the projection in terms of D is {proj_C/amp_D}\")\n",
    "print(f\"Projection occurs in bin {math.ceil(proj_C/amp_D)} \\n\")\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
